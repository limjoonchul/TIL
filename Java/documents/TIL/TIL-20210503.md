# 오늘 해야 할 일
* 프로젝트 서버에 배포하는 방법 공부하기
* kafka에 대해서 자료 찾아보고, 공부하기
* 알고리즘 3문제 이상 풀고 내용 정리

# 오늘 공부한 내용 및 느낀 점
* kafka를 학원 스프링 강의 때 설치해둔 것이 있어서 기본 예제를 포스팅 해놓은 블로그가 있길래
그걸 참고해서 따라해봤다. 해놓은걸 보니깐 정말 별거 없는데 왜이리 오래 걸렸을까싶다.
처음하는 것이고, 여러 블로그들을 보느라 또 따라해도 되는 블로그들도 있고 안되는 블로그들이 있어서
따라했다가 안되서 다른 블로그를 찾아보면서 하다보니 그렇게 된 것 같다.
너무 기본 예제여서 이론적인 내용들을 더 공부해야 적용가능할 것 같다.

* [요세푸스 문제](https://www.acmicpc.net/problem/1158)
    * 역시나 너무 어렵게 생각했다. 큐에 대한 문제였는데 이걸 큐를 이용해서 어떻게 해결할지에 대한
    아이디어를 찾지 못하고 정말 굉장히 어렵게 풀려고 하고 있다가 안되서 다른 사람의 블로그에서
    어떤식으로 접근했는지 참고해서 풀었는데, 정말 반복문을 돌리면서 변수들이 어디에 있어야 초기화가 되는지
    이런것도 고려하지 않고 푸는 것 같아서 오늘 굉장히 스스로 짜증이 났다.
# 카프카 내용 정리
## Apache Kafka
* 대용량, 대규모 메세지 데이터를 빠르게 처리하도록 개발된 메세징 플랫폼이다.
### 카프카 용어
* 브로커(Broker) : 아파치 카프카 애플리케이션이 설치되어 있는 서버 또는 노드

* 토픽(Topic) : 프로듀서(Producer)와 컨슈머(Consumer)들이 카프카로 보낸 자신들의 메시지를 구분하기 위한 네임. 다수의 프로듀서, 컨슈머들이 동일한 카프카를 사용하게 되면, 메시지들이 서로 뒤섞여 각자 자신이 원하는 메시지를 얻기가 어렵기 때문에 토픽이라는 이름으로 이를 구분하기 위해 사용함

* 프로듀서(Producer) : 메시지를 생산하여 브로커의 토픽 이름으로 보내는 서버 또는 애플리케이션

* 컨슈머(Consumer) : 브로커의 토픽 이름으로 저장된 메시지를 가져가는 서버 또는 애플리케이션

* 파티션(Partition) : 병렬처리가 가능하도록 토픽을 나눌 수 있고, 많은 양의 메시지 처리를 위해 파티션의 수를 늘려줄 수 있음

* 주키퍼(ZooKeeper) : 분산 애플리케이션을 위한 코디네이션 시스템. 분산 애플리케이션이 안정적인 서비스를 할 수 있도록 분산되어 있는 각 애플리케이션의 정보를 중앙에 집중함. 컨슈머 혹은 카프카와 직접 통신하면서 구성 관리, 그룹 관리 네이밍, 동기화 등의 서비스를 제공 

## 예제 
* 스프링 프로젝트에서 카프카를 사용하기 위해선 먼저 zookeeper와 kafka를 실행시켜야 한다.
        
* 윈도우는 /bin/windows 폴더 밑에 batch 파일을 사용하고, 리눅스라면 /bin 디렉토리 하위에 shell 파일을 사용하면 된다.
    * `bin/windows/zookeeper-server-start.bat config/zookeeper.properties` 
        * zookeeper-server-start.bat - zookeeper 서버를 실행하는 파일이다.
        * zookeeper.properties - zookeeper 서버 설정 파일이다.
            * 위 처럼 실행을 시키면 2181 포트가 기본 포트로 설정되어 실행되는데 실행이 안되고
            이미 포트가 존재한다는 에러메세지가 띄워질 때가 있는데 그럴 땐  `bin/windows/zookeeper-server-stop.bat`을
            실행하고 다시 작성하면 정상적으로 작동 된다!
    * `bin/windows/kafka-server-start.bat config/server.properties`
        * 별도의 bash를 켜서 카프카도 실행 시키면 된다.
        * 주키퍼를 실행시켜 놓고, 카프카를 실행시켰을 때 `현재 연결은 원격 호스트에 의해 강제로 끊겼습니다.`라는
        에러메세지가 띄워졌었는데 그럴 땐 server.properties의 log basic log.dirs에 있는
         kafka-logs 폴더와 zookeeper 폴더를 제거하고 다시 실행하니 정상적으로 실행이 되었다!
### bash를 이용한 간단한 테스트
1. `bin\windows\kafka-topics.bat --create --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1 --topic test`
    * 위 명령어를 통해 Topic을 생성한다.     
    * bin\windows\kafka-topics.bat --list --bootstrap-server localhost:9092 를 통해 생성된 Topic 리스트를 확인할 수 있다.
2.
```text
bin\windows\kafka-console-producer.bat --broker-list localhost:9092 --topic test
>hello kafka    
``` 
* 위 명령어처럼 토픽에 메세지를 입력한다.
3. bin\windows\kafka-console-consumer.bat --bootstrap-server localhost:9092 --topic test --from-beginning
    * 위 명령어를 입력하면 producer에서 입력한 메세지가 출력되는 것을 볼 수 있다.
    * -from-beginning
        * Consumer에게 설정된 offset이 없으므로 가장 최신의 메시지 대신 가장 먼저 도착한 메시지부터 읽도록 하는 옵션이다.
### Spring boot 프로젝트와 카프카 연동을 통한 테스트
* implementation 'org.springframework.kafka:spring-kafka' 를 통해 의존성을 추가해줘야 한다.

* application.yml
```yaml
spring:
  kafka:
    consumer:
      bootstrap-servers: localhost:9092
      group-id: foo
      auto-offset-reset: earliest
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
    producer:
      bootstrap-servers: localhost:9092
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
```
* bootstrap-servers
    * Kafka 클러스터에 대한 초기 연결에 사용할 호스트:포트쌍의 쉼표로 구분된 목록
    * 글로벌 설정이 있어도, consumer.bootstrap-servers가 존재하면 consuemer 전용으로 오버라이딩한다.
* group-id
    * Consumer는 Consumer Group이 존재하기 때문에, 유일하게 식별 가능한 Consumer Group을 작성한다.
* auto-offset-reset
    * Kafka 서버에 초기 offset이 없거나, 서버에 현재 offset이 더 이상 없는 경우 수행할 작업을 작성한다.
    * Consumer Group의 Consumer는 메시지를 소비할 때 Topic내에 Partition에서 다음에 소비할 offset이 어디인지 공유를 하고 있습니다. 그런데 오류 등으로 인해. 이러한 offset 정보가 없어졌을 때 어떻게 offeset을 reset 할 것인지를 명시한다.
        * latest : 가장 최근에 생산된 메시지로 offeset reset
        * earliest : 가장 오래된 메시지로 offeset reset
        * none : offset 정보가 없으면 Exception 발생
    * 직접 Kafka Server에 접근하여 offset을 reset할 수 있지만, Spring에서 제공해주는 방식은 위와 같다.
* key-deserializer / value-deserializer
    * Kafka에서 데이터를 받아올 때, key / value를 역직렬화 한다.
    * 여기서 key와 value는 뒤에서 살펴볼 KafkaTemplate의 key, value를 의미한다.
    * 메시지가 문자열 데이터이므로 StringDeserializer를 사용. JSON 데이터를 넘겨줄 것이라면 JsonDeserializer도 가능하다.

#### Controller
```java
package com.example.kafka.springbootwithkafka.controller;

import com.example.kafka.springbootwithkafka.engine.Producer;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.web.bind.annotation.*;

@RestController
@RequestMapping(value = "/kafka")
public class KafkaController {

    private final Producer producer;

    @Autowired
    public KafkaController(Producer producer) {
        this.producer = producer;
    }

    @GetMapping("/")
    public String hello() {
        return "Hello";
    }

    @PostMapping(value = "/publish")
    public String sendMessageToKafkaTopic(@RequestParam("message") String message) {
        this.producer.sendMessage(message); // Post로 메세지가 넘겨오면 Producer 서비스로 전달.
        return "success";
    }
}
```

#### Producer
```java
package com.example.kafka.springbootwithkafka.engine;

import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.kafka.core.KafkaTemplate;
import org.springframework.stereotype.Service;

@Service
public class Producer {

    private static final String TOPIC = "users";

    private final KafkaTemplate<String, String> kafkaTemplate;

    @Autowired
    public Producer(KafkaTemplate kafkaTemplate) {
        this.kafkaTemplate = kafkaTemplate;
    }

    public void sendMessage(String message) {
        System.out.println("Producer.sendMessage = " + message);
        this.kafkaTemplate.send(TOPIC, message);
    }

}
```

#### Consumer
```java
package com.example.kafka.springbootwithkafka.engine;

import org.springframework.kafka.annotation.KafkaListener;
import org.springframework.stereotype.Service;

import java.io.IOException;

@Service
public class Consumer {
    
    @KafkaListener(topics = "users", groupId = "group-id")
    public void consume(String message) throws IOException {
        System.out.println("Consumed message = " + message);
    }
}
```

### 참고
* [예제 블로그](https://victorydntmd.tistory.com/348)
* [이론 블로그](https://twofootdog.tistory.com/86)